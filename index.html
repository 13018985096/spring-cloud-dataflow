---
# The name of your project
title: Spring Cloud Data Flow

badges:

  # Specify your project's twitter handle, if any. Delete if none.
  twitter: SpringData

  # Customize your project's badges. Delete any entries that do not apply.
  custom:
    - name: Source (GitHub)
      url:  https://github.com/spring-cloud/spring-cloud-dataflow
      icon: github

    - name: CI (Bamboo)
      url:  https://build.spring.io/browse/SCD
      icon: ci

    - name: StackOverflow
      url:  http://stackoverflow.com/questions/tagged/spring-cloud
      icon: stackoverflow

---
<!DOCTYPE HTML>
<html lang="en-US">

<!-- Specify the parent of this project (or delete if none) to influence the rendering of the breadcrumb -->
{% capture parent_link %}
[Spring Cloud]({{ site.projects_site_url }}/spring-cloud)
{% endcapture %}


{% capture billboard_description %}

A cloud native programming and operating model for composable data microservices on a structured platform. It allows 
developers to create, orchestrate and refactor data pipelines with a single programming model for common use cases 
like data ingest, real time analytics, and data import/export.

{% endcapture %}

{% capture main_content %}

Spring Cloud Data Flow is the cloud native redesign of [Spring XD](http://projects.spring.io/spring-xd/) - a project that 
aimed to simplify Big Data application development. Existing integration and batch modules are refactored as Spring Boot 
data microservices that are now autonomous deployment units – thus enabling them to take full advantage of environment 
capabilities "natively" and they can independently evolve in isolation.

Spring Cloud Data Flow defines the best practices for distributed stream and batch data microservices.

## Features

* Orchestrate applications across a variety of distributed runtime platforms including: Cloud Foundry, Lattice, and Apache YARN
* Separate runtime dependencies backed by ‘spring profiles’
* Consume stream and batch microservices as maven dependency and push it to production
* Develop using: DSL, Shell, REST-APIs, Admin-UI, and Flo
* Take advantage of metrics, health checks and remote management functionalities
* Scale stream and batch pipelines without interrupting data flows

<span id="quick-start"></span>
## Quick Start

Step 1 - Clone [Spring Cloud Data Flow](https://github.com/spring-cloud/spring-cloud-dataflow) repository

Step 2 - Build Project
```
mvn clean package
```

Step 3 - Start
```
redis-server
```

Step 4 - Launch **‘local’** Implementation of Admin: 
```
java -jar spring-cloud-dataflow-admin/target/spring-cloud-dataflow-admin***.jar 
```

Step 5 - Launch Shell
```
java -jar spring-cloud-dataflow-shell/target/spring-cloud-dataflow-shell***.jar
```

Step 6 - Create **‘ticktock’** Stream using the Shell
```
dataflow:>stream create ticktock --definition "time | log" --deploy
```

Step 7 - Launch Admin UI
http://localhost:9393/admin-ui

{% endcapture %}

{% capture related_resources %}

### Related Projects

* [Spring Cloud Stream]({{site.projects_site_url}}/spring-cloud-stream/)
* [Spring Cloud Stream Modules]({{site.projects_site_url}}/spring-cloud-stream-modules/)
* [Spring XD]({{site.projects_site_url}}/spring-xd/)

{% endcapture %}


{% include project_page.html %}
</html>
